You were assigned to refactor this project code in order to simplify the audio recording procedure. It seems that there is two methods for capturing audio, one in the backend via Rust and one in the frontend using Web Speech API. Your task is to make the `recording -> transcript -> translate` pipeline as simple as possible but working robustly. Remove the conflicting recording schemes, keep only the Web Speech API for voice recording. The VAD workflow seems okay, just ensure bigger chunks (5s or more) so whisper API can successfully detect language correctly. ensure that there is nothing stopping the audio recording besides user action (record button click or hotkey press or program/API exceptions - silence is not a reason for stopping the recording, but exceeded time/length is). At the end of the audio recording the Original Text field in the main page must contain the full audio transcription and the "Translated Text" should contain the correct / translated version after final LLM response. 